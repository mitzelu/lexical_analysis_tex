\section*{Conclusions}

\pagenumbering{arabic}
\setcounter{page}{61}
\phantomsection

Together with the evolution of the internet, social media channels become an important marketing tool. In the last years placing advertising content on the most popular social media channels was a strong marketing tool used by companies. Now, with the growing number of users that has ad blocks, software programs that prevent ads from being shown on websites, the impact of marketing approach decreased considerably. In this context, bloggers emerges as an influential new media outlet for PR stories and product reviews.

Finduber project aim is to research the algorithms and methods of lexical analysis and text mining in process of extracting useful information from unstructured data of social media. Main goal is to develope a search engine based on lexical analysis that will take as an input argument a keyword given by user. Further the algorithm should assign the given keyword to an existing category and based on it to extract influential bloggers from Youtube database from categoy domain.

The main contributions of this topic are:

\begin{itemize}
\item[--] A taxonomy database that contains categories and subcategories of four pre-defined industries. 

\item[--] Research of machine learning algorithms and text mining methods for natural language processing and labeling of unstructured data.

\item[--] An analysis of new techniques for big data processing and analysing in optimal amount of time. 

\item[--] A algorithm based on text mining methods that has the purpose to classify unstructured data.
\end{itemize}

Building the application required many multi-step planning of the infrastructure. One problem encountered with taxonomy database is that abstracts words usually are hard to defined and relate to other non-avstract words. Simply use of hypernym/hyponym tree does not solve the problem. To solve the problem was researched different algorithms and approaches that deals with semantic similarities of words. Wordnet library, fuzzy algorithm, k-means and cosine similarity are some of the methods analyzed. At the end wikipedia category tree was chosen as most suitable approach to solve the problem, because it has a hierarchical structure of categories and subcategories.

Another major problem encountered while developing the platform is the unstructured data classification. Social media data that comes from user's comments or channel descriptions do not follow some rules. In this context is quite hard to train a classifier that will label the data. The problem is also related with natural language processing. 


\newpage

Current project works only with English language text. Also, the taxonomy database is limited and do not work properly with any given word. The user interface page has poor functionalities and did not provide all specified requirements defined at the beinning.
Thus, a number of important model improvements have been found to be necessary:

\begin{itemize}
\item[--] Improve the quality of text corpus used as test set.

\item[--] ;;;
\end{itemize}



\clearpage